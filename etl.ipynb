{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# ETL Processes\n",
    "We'll use this notebook to develop the ETL process for each of the database tables before completing the `etl.py` file to load the whole datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import psycopg2\n",
    "import json\n",
    "import pandas as pd\n",
    "from sql_queries import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\"host=127.0.0.1 dbname=sparkifydb user=student password=student\")\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_files(filepath):\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(filepath):\n",
    "        files = glob.glob(os.path.join(root,'*.json'))\n",
    "        for f in files :\n",
    "            all_files.append(os.path.abspath(f))\n",
    "    \n",
    "    return all_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Process `song_data`\n",
    "In this first part wel'll perform ETL on the first dataset, `song_data`, to create the `songs` and `artists` dimensional tables.\n",
    "\n",
    "\n",
    "- The `get_files` function defined above is used to get a list of all song JSON files in `data/song_data`.\n",
    "- A new function is defined to loop over all the json song files and combine their contents in a new json fie in the project's root directory.\n",
    "- The data is filtered to create new `song_data` and `artist_data` variables.\n",
    "- The filtered data is saved to csv files in the project's root directory.\n",
    "- the `song_data` and `artist_data` are inserted in bulk into the `songs` table and `artists` table respectively using the `COPY` command with pre-defined bulk insert queries from the `sql_queries.py` file which is much faster compared to using single insert queries in a `for` loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "song_files = get_files('data/song_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def merge_json_files(files):\n",
    "    result = list()\n",
    "    fname = 'all_songs.json'\n",
    "    for f in files:\n",
    "        with open(f, 'r') as infile:\n",
    "            result.append(json.load(infile))\n",
    "\n",
    "    with open(fname, 'w') as output_file:\n",
    "        json.dump(result, output_file, indent=0)\n",
    "        return fname\n",
    "\n",
    "\n",
    "json_file = merge_json_files(song_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist_latitude</th>\n",
       "      <th>artist_location</th>\n",
       "      <th>artist_longitude</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>duration</th>\n",
       "      <th>num_songs</th>\n",
       "      <th>song_id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARD7TVE1187B99BFB1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>California - LA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Casual</td>\n",
       "      <td>218.93179</td>\n",
       "      <td>1</td>\n",
       "      <td>SOMZWCG12A8C13C480</td>\n",
       "      <td>I Didn't Mean To</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARNTLGG11E2835DDB9</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clp</td>\n",
       "      <td>266.39628</td>\n",
       "      <td>1</td>\n",
       "      <td>SOUDSGM12AC9618304</td>\n",
       "      <td>Insatiable (Instrumental Version)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AR8ZCNI1187B9A069B</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>Planet P Project</td>\n",
       "      <td>269.81832</td>\n",
       "      <td>1</td>\n",
       "      <td>SOIAZJW12AB01853F1</td>\n",
       "      <td>Pink World</td>\n",
       "      <td>1984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AR10USD1187B99F3F1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Burlington, Ontario, Canada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tweeterfriendly Music</td>\n",
       "      <td>189.57016</td>\n",
       "      <td>1</td>\n",
       "      <td>SOHKNRJ12A6701D1F8</td>\n",
       "      <td>Drop of Rain</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARMJAGH1187FB546F3</td>\n",
       "      <td>35.14968</td>\n",
       "      <td>Memphis, TN</td>\n",
       "      <td>-90.04892</td>\n",
       "      <td>The Box Tops</td>\n",
       "      <td>148.03546</td>\n",
       "      <td>1</td>\n",
       "      <td>SOCIWDW12A8C13D406</td>\n",
       "      <td>Soul Deep</td>\n",
       "      <td>1969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            artist_id  artist_latitude              artist_location  \\\n",
       "0  ARD7TVE1187B99BFB1              NaN              California - LA   \n",
       "1  ARNTLGG11E2835DDB9              NaN                                \n",
       "2  AR8ZCNI1187B9A069B              NaN                                \n",
       "3  AR10USD1187B99F3F1              NaN  Burlington, Ontario, Canada   \n",
       "4  ARMJAGH1187FB546F3         35.14968                  Memphis, TN   \n",
       "\n",
       "   artist_longitude            artist_name   duration  num_songs  \\\n",
       "0               NaN                 Casual  218.93179          1   \n",
       "1               NaN                    Clp  266.39628          1   \n",
       "2               NaN       Planet P Project  269.81832          1   \n",
       "3               NaN  Tweeterfriendly Music  189.57016          1   \n",
       "4         -90.04892           The Box Tops  148.03546          1   \n",
       "\n",
       "              song_id                              title  year  \n",
       "0  SOMZWCG12A8C13C480                   I Didn't Mean To     0  \n",
       "1  SOUDSGM12AC9618304  Insatiable (Instrumental Version)     0  \n",
       "2  SOIAZJW12AB01853F1                         Pink World  1984  \n",
       "3  SOHKNRJ12A6701D1F8                       Drop of Rain     0  \n",
       "4  SOCIWDW12A8C13D406                          Soul Deep  1969  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(json_file, lines=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## #1: `songs` Table\n",
    "#### Extracting Data for Songs Table\n",
    "- we'll extract columns for song ID, title, artist ID, year, and duration.\n",
    "\n",
    "\n",
    "- The data will be checked for duplicate values in the song Id column and the duplicates will be dropped.\n",
    "\n",
    "\n",
    "- The data will be saved to a `csv` file in the project's root directory.\n",
    "\n",
    "\n",
    "- The data will be inserted in bulk to the songs table from the `csv` file using the `song_table_bulk_insert` query\n",
    "  that is imported from the `sql_queries.py` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>title</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>year</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SOMZWCG12A8C13C480</td>\n",
       "      <td>I Didn't Mean To</td>\n",
       "      <td>ARD7TVE1187B99BFB1</td>\n",
       "      <td>0</td>\n",
       "      <td>218.93179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SOUDSGM12AC9618304</td>\n",
       "      <td>Insatiable (Instrumental Version)</td>\n",
       "      <td>ARNTLGG11E2835DDB9</td>\n",
       "      <td>0</td>\n",
       "      <td>266.39628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SOIAZJW12AB01853F1</td>\n",
       "      <td>Pink World</td>\n",
       "      <td>AR8ZCNI1187B9A069B</td>\n",
       "      <td>1984</td>\n",
       "      <td>269.81832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SOHKNRJ12A6701D1F8</td>\n",
       "      <td>Drop of Rain</td>\n",
       "      <td>AR10USD1187B99F3F1</td>\n",
       "      <td>0</td>\n",
       "      <td>189.57016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SOCIWDW12A8C13D406</td>\n",
       "      <td>Soul Deep</td>\n",
       "      <td>ARMJAGH1187FB546F3</td>\n",
       "      <td>1969</td>\n",
       "      <td>148.03546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              song_id                              title           artist_id  \\\n",
       "0  SOMZWCG12A8C13C480                   I Didn't Mean To  ARD7TVE1187B99BFB1   \n",
       "1  SOUDSGM12AC9618304  Insatiable (Instrumental Version)  ARNTLGG11E2835DDB9   \n",
       "2  SOIAZJW12AB01853F1                         Pink World  AR8ZCNI1187B9A069B   \n",
       "3  SOHKNRJ12A6701D1F8                       Drop of Rain  AR10USD1187B99F3F1   \n",
       "4  SOCIWDW12A8C13D406                          Soul Deep  ARMJAGH1187FB546F3   \n",
       "\n",
       "   year   duration  \n",
       "0     0  218.93179  \n",
       "1     0  266.39628  \n",
       "2  1984  269.81832  \n",
       "3     0  189.57016  \n",
       "4  1969  148.03546  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_data = df[['song_id', 'title', 'artist_id', 'year', 'duration']]\n",
    "song_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Now we will check the the `song_id` column for duplicate values and drop them if they exist becuase inserting data in bulk using the `COPY` command while much faster and more efficient does not currently (at the time of doing this project) support combining it with the `ON CONFLICT` statement outside \"AnalyticDB\"..., we could get around that by using a temporary unconstrained table (by unique primary key or a desired constraint in general) to get the data from the csv and then insert it to the main table we intend to keep but even then the `ON CONFLICT` statement currently allows only one duplicate for a given row in this context.\n",
    "\n",
    "so for this table... since the data is not big we'll clean the data using python before inserting, but if the data was much bigger and was collected so that it woudn't have more than one duplicate per row... then using the solution mentioned above and letting sql handle it would be more efficient since sql handles data processing better than python..., also if this was used in a production pipeline (depending on the data size and database hosting service capacity and availability) doing so could take some load of the main server/service hosting the back-end and let sql handle it more efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    71\n",
       "True      3\n",
       "Name: song_id, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking duplicate values for the song_id column\n",
    "song_data.song_id.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Dropping duplicates while keeping the last value and hence the last update to info assotiated with the song id\n",
    "song_data.drop_duplicates(subset='song_id', keep='last', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    71\n",
       "Name: song_id, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirming duplicates drop\n",
    "song_data.song_id.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Inserting Records into Song Table\n",
    "- we'll save the cleaned data into a `csv` file\n",
    "- We'll implement `song_table_bulk_insert` query from `sql_queries.py` to copy the data from the `csv` file and insert it in bulk which is much faster and more efficient than using a `for` loop to loop over the rows doing single inserts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "song_fname = 'songs.csv'\n",
    "\n",
    "# Saving the song data to a csv file\n",
    "song_data.to_csv(song_fname, index=False) # Removing the extra csv index between to match the columns for bulk data insert\n",
    "\n",
    "# Getting the current working directory path\n",
    "working_dir = os.getcwd()\n",
    "\n",
    "song_data_path = f\"{working_dir}/{song_fname}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Copying the data from the csv file to the database table\n",
    "with open(song_data_path, 'r') as f:\n",
    "    cur.copy_expert(sql=song_table_bulk_insert, file=f)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Run `test.ipynb` to see if you've successfully added a record to this table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## #2: `artists` Table\n",
    "#### Extracting Data for Artists Table\n",
    "\n",
    "The artist data will be extracted, checked, prepared and then saved into a csv file in the same manner used before with the song table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>artist_location</th>\n",
       "      <th>artist_latitude</th>\n",
       "      <th>artist_longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARD7TVE1187B99BFB1</td>\n",
       "      <td>Casual</td>\n",
       "      <td>California - LA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARNTLGG11E2835DDB9</td>\n",
       "      <td>Clp</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AR8ZCNI1187B9A069B</td>\n",
       "      <td>Planet P Project</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AR10USD1187B99F3F1</td>\n",
       "      <td>Tweeterfriendly Music</td>\n",
       "      <td>Burlington, Ontario, Canada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARMJAGH1187FB546F3</td>\n",
       "      <td>The Box Tops</td>\n",
       "      <td>Memphis, TN</td>\n",
       "      <td>35.14968</td>\n",
       "      <td>-90.04892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            artist_id            artist_name              artist_location  \\\n",
       "0  ARD7TVE1187B99BFB1                 Casual              California - LA   \n",
       "1  ARNTLGG11E2835DDB9                    Clp                                \n",
       "2  AR8ZCNI1187B9A069B       Planet P Project                                \n",
       "3  AR10USD1187B99F3F1  Tweeterfriendly Music  Burlington, Ontario, Canada   \n",
       "4  ARMJAGH1187FB546F3           The Box Tops                  Memphis, TN   \n",
       "\n",
       "   artist_latitude  artist_longitude  \n",
       "0              NaN               NaN  \n",
       "1              NaN               NaN  \n",
       "2              NaN               NaN  \n",
       "3              NaN               NaN  \n",
       "4         35.14968         -90.04892  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist_data = df[['artist_id', 'artist_name', 'artist_location', 'artist_latitude', 'artist_longitude']]\n",
    "artist_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    69\n",
       "True      5\n",
       "Name: artist_id, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cheking for duplicate artist id values\n",
    "artist_data.artist_id.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Dropping duplicate values\n",
    "artist_data.drop_duplicates(subset='artist_id', keep='last', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    69\n",
       "Name: artist_id, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirming duplicates drop\n",
    "artist_data.artist_id.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Insert Record into Artist Table\n",
    "Implement the `artist_table_insert` query in `sql_queries.py` and run the cell below to insert a record for this song's artist into the `artists` table. Remember to run `create_tables.py` before running the cell below to ensure you've created/resetted the `artists` table in the sparkify database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "artist_fname = 'artists.csv'\n",
    "\n",
    "# Saving artist data to a csv file\n",
    "artist_data.to_csv(artist_fname, index=False) # Removing the extra csv index between to match the columns for bulk data insert\n",
    "\n",
    "# Getting the current working directory path\n",
    "working_dir = os.getcwd()\n",
    "\n",
    "artist_data_path = f\"{working_dir}/{artist_fname}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Copying the data from the csv to the database table\n",
    "with open(artist_data_path, 'r') as f:\n",
    "    cur.copy_expert(sql=artist_table_bulk_insert, file=f)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Process `log_data`\n",
    "In this part, we'll perform ETL on the second dataset, `log_data`, to create the `time` and `users` dimensional tables, as well as the `songplays` fact table.\n",
    "\n",
    "- The `get_files` function is used to get all the log data file paths.\n",
    "\n",
    "- A function is defined to loop over all log files extracting their data and appending it to a dataframe.\n",
    "\n",
    "- We'll extract the time data and user data, check it, clean it, pre-process it and then save it to a csv file and bulk insert each file to it's respective database table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Getting the log data file paths\n",
    "log_files = get_files('data/log_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# looping over the files and importing the data from all files in a dataframe\n",
    "def merge_LogFiles(file_names):\n",
    "    df_temp = None\n",
    "    for file in file_names:\n",
    "        if df_temp is not None:\n",
    "            df_temp = df_temp.append(pd.read_json(file, lines=True), ignore_index=True)\n",
    "        elif df_temp is None:\n",
    "            df_temp = pd.read_json(file, lines=True)\n",
    "    return df_temp\n",
    "\n",
    "df = merge_LogFiles(log_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8056, 18)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cheking the amount of data / dataframe dimensions\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## #3: `time` Table\n",
    "#### Extracting Data for Time Table\n",
    "\n",
    "- we'll filter records by `NextSong` action.\n",
    "- We'll convert the `ts` timestamp column to datetime and extract useful datetime data from it using the pandas `dt` attribute.\n",
    "    - We'll extract the timestamp, hour, day, week of year, month, year, and weekday from the `ts` column and set `time_data` to a dataframe containing these\n",
    "      values in order.     \n",
    "- We'll specify labels for these columns and set to `column_labels`.\n",
    "- We'll create a dataframe, `time_df,` containing the time data for this file by combining `column_labels` and `time_data` into a dictionary and converting this\n",
    "  into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>auth</th>\n",
       "      <th>firstName</th>\n",
       "      <th>gender</th>\n",
       "      <th>itemInSession</th>\n",
       "      <th>lastName</th>\n",
       "      <th>length</th>\n",
       "      <th>level</th>\n",
       "      <th>location</th>\n",
       "      <th>method</th>\n",
       "      <th>page</th>\n",
       "      <th>registration</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>song</th>\n",
       "      <th>status</th>\n",
       "      <th>ts</th>\n",
       "      <th>userAgent</th>\n",
       "      <th>userId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stephen Lynch</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Jayden</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Bell</td>\n",
       "      <td>182.85669</td>\n",
       "      <td>free</td>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1.540992e+12</td>\n",
       "      <td>829</td>\n",
       "      <td>Jim Henson's Dead</td>\n",
       "      <td>200</td>\n",
       "      <td>1543537327796</td>\n",
       "      <td>Mozilla/5.0 (compatible; MSIE 10.0; Windows NT...</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Manowar</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Jacob</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Klein</td>\n",
       "      <td>247.56200</td>\n",
       "      <td>paid</td>\n",
       "      <td>Tampa-St. Petersburg-Clearwater, FL</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1.540558e+12</td>\n",
       "      <td>1049</td>\n",
       "      <td>Shell Shock</td>\n",
       "      <td>200</td>\n",
       "      <td>1543540121796</td>\n",
       "      <td>\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Morcheeba</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Jacob</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>Klein</td>\n",
       "      <td>257.41016</td>\n",
       "      <td>paid</td>\n",
       "      <td>Tampa-St. Petersburg-Clearwater, FL</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1.540558e+12</td>\n",
       "      <td>1049</td>\n",
       "      <td>Women Lose Weight (Feat: Slick Rick)</td>\n",
       "      <td>200</td>\n",
       "      <td>1543540368796</td>\n",
       "      <td>\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Jacob</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>Klein</td>\n",
       "      <td>231.23546</td>\n",
       "      <td>paid</td>\n",
       "      <td>Tampa-St. Petersburg-Clearwater, FL</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1.540558e+12</td>\n",
       "      <td>1049</td>\n",
       "      <td>Won't Go Home Without You</td>\n",
       "      <td>200</td>\n",
       "      <td>1543540625796</td>\n",
       "      <td>\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Jacob</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>Klein</td>\n",
       "      <td>216.76363</td>\n",
       "      <td>paid</td>\n",
       "      <td>Tampa-St. Petersburg-Clearwater, FL</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1.540558e+12</td>\n",
       "      <td>1049</td>\n",
       "      <td>Hey_ Soul Sister</td>\n",
       "      <td>200</td>\n",
       "      <td>1543540856796</td>\n",
       "      <td>\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          artist       auth firstName gender  itemInSession lastName  \\\n",
       "0  Stephen Lynch  Logged In    Jayden      M              0     Bell   \n",
       "1        Manowar  Logged In     Jacob      M              0    Klein   \n",
       "2      Morcheeba  Logged In     Jacob      M              1    Klein   \n",
       "3       Maroon 5  Logged In     Jacob      M              2    Klein   \n",
       "4          Train  Logged In     Jacob      M              3    Klein   \n",
       "\n",
       "      length level                             location method      page  \\\n",
       "0  182.85669  free      Dallas-Fort Worth-Arlington, TX    PUT  NextSong   \n",
       "1  247.56200  paid  Tampa-St. Petersburg-Clearwater, FL    PUT  NextSong   \n",
       "2  257.41016  paid  Tampa-St. Petersburg-Clearwater, FL    PUT  NextSong   \n",
       "3  231.23546  paid  Tampa-St. Petersburg-Clearwater, FL    PUT  NextSong   \n",
       "4  216.76363  paid  Tampa-St. Petersburg-Clearwater, FL    PUT  NextSong   \n",
       "\n",
       "   registration  sessionId                                  song  status  \\\n",
       "0  1.540992e+12        829                     Jim Henson's Dead     200   \n",
       "1  1.540558e+12       1049                           Shell Shock     200   \n",
       "2  1.540558e+12       1049  Women Lose Weight (Feat: Slick Rick)     200   \n",
       "3  1.540558e+12       1049             Won't Go Home Without You     200   \n",
       "4  1.540558e+12       1049                      Hey_ Soul Sister     200   \n",
       "\n",
       "              ts                                          userAgent userId  \n",
       "0  1543537327796  Mozilla/5.0 (compatible; MSIE 10.0; Windows NT...     91  \n",
       "1  1543540121796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     73  \n",
       "2  1543540368796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     73  \n",
       "3  1543540625796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     73  \n",
       "4  1543540856796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     73  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df.page == 'NextSong']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2018-11-30 00:22:07.796\n",
       "1   2018-11-30 01:08:41.796\n",
       "2   2018-11-30 01:12:48.796\n",
       "3   2018-11-30 01:17:05.796\n",
       "4   2018-11-30 01:20:56.796\n",
       "Name: ts, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = pd.to_datetime(df['ts'] , unit='ms')\n",
    "t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "time_data = (t, t.dt.hour, t.dt.day, t.dt.week , t.dt.month, t.dt.year, t.dt.weekday)\n",
    "column_labels = ('timestamp', 'hour', 'day', 'week of year', 'month', 'year', 'weekday')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>week of year</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-11-30 00:22:07.796</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>48</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-11-30 01:08:41.796</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>48</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-11-30 01:12:48.796</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>48</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-11-30 01:17:05.796</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>48</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-11-30 01:20:56.796</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>48</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp  hour  day  week of year  month  year  weekday\n",
       "0 2018-11-30 00:22:07.796     0   30            48     11  2018        4\n",
       "1 2018-11-30 01:08:41.796     1   30            48     11  2018        4\n",
       "2 2018-11-30 01:12:48.796     1   30            48     11  2018        4\n",
       "3 2018-11-30 01:17:05.796     1   30            48     11  2018        4\n",
       "4 2018-11-30 01:20:56.796     1   30            48     11  2018        4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_df = pd.DataFrame.from_dict(dict(zip(column_labels,time_data)))\n",
    "time_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Insert Records into Time Table\n",
    "\n",
    "- We'll save the time data into a `csv` file.\n",
    "\n",
    "- We'll implement the `time_table_bulk_insert` query from `sql_queries.py` and insert the data in bulk from the `csv` file into the database table using the `copy` command along with the technique mentioned earlier (creating a temporary unconstrained table and inserting the csv data into it then copying it to the main time table to be able to handle rare timestamp conflicts) becuase the combined amount of data is bigger and it would be more efficient to copy it in bulk and let sql do the processing that inserting single lines by using a `for` loop or letting python do process the data for occasional duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "time_fname = 'time.csv'\n",
    "\n",
    "# Saving time data into a csv file\n",
    "time_df.to_csv(time_fname, index=False) # Removing the extra csv index between to match the columns for bulk data insert\n",
    "\n",
    "# Getting the current working directory path\n",
    "working_dir = os.getcwd()\n",
    "\n",
    "time_data_path = f\"{working_dir}/{time_fname}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Copying the time data from the csv file into the database table\n",
    "with open(time_data_path, 'r') as f:\n",
    "    cur.copy_expert(sql=time_table_bulk_insert, file=f)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Run `test.ipynb` to see if you've successfully added records to this table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## #4: `users` Table\n",
    "#### Extracting Data for Users Table\n",
    "We'll extract user data, check it, clean it, pre-process it and then save it to a csv file and insert it in bulk to the database table in the same manner as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6820, 5) userId       object\n",
      "firstName    object\n",
      "lastName     object\n",
      "gender       object\n",
      "level        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Extracting user data\n",
    "user_df = df[['userId', 'firstName', 'lastName', 'gender', 'level']]\n",
    "# Cheking data dimensions and properties\n",
    "print(user_df.shape, user_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We'll transform the user_id data type from object to int to avoid any problems with duplicate value evaluations (missing some duplicates). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 5)\n",
      "False    96\n",
      "Name: userId, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/generic.py:4405: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>firstName</th>\n",
       "      <th>lastName</th>\n",
       "      <th>gender</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91</td>\n",
       "      <td>Jayden</td>\n",
       "      <td>Bell</td>\n",
       "      <td>M</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73</td>\n",
       "      <td>Jacob</td>\n",
       "      <td>Klein</td>\n",
       "      <td>M</td>\n",
       "      <td>paid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>86</td>\n",
       "      <td>Aiden</td>\n",
       "      <td>Hess</td>\n",
       "      <td>M</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>24</td>\n",
       "      <td>Layla</td>\n",
       "      <td>Griffin</td>\n",
       "      <td>F</td>\n",
       "      <td>paid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>26</td>\n",
       "      <td>Ryan</td>\n",
       "      <td>Smith</td>\n",
       "      <td>M</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>49</td>\n",
       "      <td>Chloe</td>\n",
       "      <td>Cuevas</td>\n",
       "      <td>F</td>\n",
       "      <td>paid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>57</td>\n",
       "      <td>Katherine</td>\n",
       "      <td>Gay</td>\n",
       "      <td>F</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>30</td>\n",
       "      <td>Avery</td>\n",
       "      <td>Watkins</td>\n",
       "      <td>F</td>\n",
       "      <td>paid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>92</td>\n",
       "      <td>Ryann</td>\n",
       "      <td>Smith</td>\n",
       "      <td>F</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>74</td>\n",
       "      <td>Braden</td>\n",
       "      <td>Parker</td>\n",
       "      <td>M</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId  firstName lastName gender level\n",
       "0        91     Jayden     Bell      M  free\n",
       "1        73      Jacob    Klein      M  paid\n",
       "23       86      Aiden     Hess      M  free\n",
       "30       24      Layla  Griffin      F  paid\n",
       "40       26       Ryan    Smith      M  free\n",
       "59       49      Chloe   Cuevas      F  paid\n",
       "62       57  Katherine      Gay      F  free\n",
       "69       30      Avery  Watkins      F  paid\n",
       "79       92      Ryann    Smith      F  free\n",
       "125      74     Braden   Parker      M  free"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transorming the \"userId\" column data type from object to int\n",
    "user_df.userId = pd.to_numeric(user_df.userId)\n",
    "\n",
    "# Dropping dublicate values\n",
    "user_df.drop_duplicates(subset='userId', inplace=True)\n",
    "\n",
    "# Confirming duplicate values drop\n",
    "print(user_df.shape)\n",
    "print(user_df.userId.duplicated().value_counts())\n",
    "\n",
    "user_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Insert Records into Users Table\n",
    "We'll mplement the `user_table_bulk_insert` query from `sql_queries.py` to insert the data in bulk from the `csv` file into the database table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "user_fname = 'users.csv'\n",
    "\n",
    "# Saving the data into a csv file \n",
    "user_df.to_csv(user_fname, index=False) # Removing the extra csv index between to match the columns for bulk data insert\n",
    "\n",
    "# Getting the current working directory path\n",
    "working_dir = os.getcwd()\n",
    "\n",
    "user_data_path = f\"{working_dir}/{user_fname}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Copying the user data from the csv file into the database table\n",
    "with open(user_data_path, 'r') as f:\n",
    "    cur.copy_expert(sql=user_table_bulk_insert, file=f)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## #5: `songplays` Table\n",
    "#### Extracting Data and Songplays Table\n",
    "\n",
    "- We'll extract the songplay table data from the log data minus the song id and artist id and save it into a csv file.\n",
    "\n",
    "- then we'll copy data and insert it in bulk from the csv file into a temporary table called records **implementing the `songplay_table_bulk_insert` query from `sql_querie.py`**.\n",
    "\n",
    "#### Insert Records into Songplays Table\n",
    "We'll select the full songplay data (including song id and artist id) from the left outer join (to keep all records even in the absence of song id and artist id) of the records table and songs table on matching song names **implementing the `songplay_table_bulk_insert` query from `sql_querie.py`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    6820\n",
       "Name: song, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cheking for null values\n",
    "df.song.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>auth</th>\n",
       "      <th>firstName</th>\n",
       "      <th>gender</th>\n",
       "      <th>itemInSession</th>\n",
       "      <th>lastName</th>\n",
       "      <th>length</th>\n",
       "      <th>level</th>\n",
       "      <th>location</th>\n",
       "      <th>method</th>\n",
       "      <th>page</th>\n",
       "      <th>registration</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>song</th>\n",
       "      <th>status</th>\n",
       "      <th>ts</th>\n",
       "      <th>userAgent</th>\n",
       "      <th>userId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stephen Lynch</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Jayden</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Bell</td>\n",
       "      <td>182.85669</td>\n",
       "      <td>free</td>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1.540992e+12</td>\n",
       "      <td>829</td>\n",
       "      <td>Jim Henson's Dead</td>\n",
       "      <td>200</td>\n",
       "      <td>1543537327796</td>\n",
       "      <td>Mozilla/5.0 (compatible; MSIE 10.0; Windows NT...</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Manowar</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Jacob</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Klein</td>\n",
       "      <td>247.56200</td>\n",
       "      <td>paid</td>\n",
       "      <td>Tampa-St. Petersburg-Clearwater, FL</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1.540558e+12</td>\n",
       "      <td>1049</td>\n",
       "      <td>Shell Shock</td>\n",
       "      <td>200</td>\n",
       "      <td>1543540121796</td>\n",
       "      <td>\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Morcheeba</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Jacob</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>Klein</td>\n",
       "      <td>257.41016</td>\n",
       "      <td>paid</td>\n",
       "      <td>Tampa-St. Petersburg-Clearwater, FL</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1.540558e+12</td>\n",
       "      <td>1049</td>\n",
       "      <td>Women Lose Weight (Feat: Slick Rick)</td>\n",
       "      <td>200</td>\n",
       "      <td>1543540368796</td>\n",
       "      <td>\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Jacob</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>Klein</td>\n",
       "      <td>231.23546</td>\n",
       "      <td>paid</td>\n",
       "      <td>Tampa-St. Petersburg-Clearwater, FL</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1.540558e+12</td>\n",
       "      <td>1049</td>\n",
       "      <td>Won't Go Home Without You</td>\n",
       "      <td>200</td>\n",
       "      <td>1543540625796</td>\n",
       "      <td>\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Jacob</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>Klein</td>\n",
       "      <td>216.76363</td>\n",
       "      <td>paid</td>\n",
       "      <td>Tampa-St. Petersburg-Clearwater, FL</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1.540558e+12</td>\n",
       "      <td>1049</td>\n",
       "      <td>Hey_ Soul Sister</td>\n",
       "      <td>200</td>\n",
       "      <td>1543540856796</td>\n",
       "      <td>\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          artist       auth firstName gender  itemInSession lastName  \\\n",
       "0  Stephen Lynch  Logged In    Jayden      M              0     Bell   \n",
       "1        Manowar  Logged In     Jacob      M              0    Klein   \n",
       "2      Morcheeba  Logged In     Jacob      M              1    Klein   \n",
       "3       Maroon 5  Logged In     Jacob      M              2    Klein   \n",
       "4          Train  Logged In     Jacob      M              3    Klein   \n",
       "\n",
       "      length level                             location method      page  \\\n",
       "0  182.85669  free      Dallas-Fort Worth-Arlington, TX    PUT  NextSong   \n",
       "1  247.56200  paid  Tampa-St. Petersburg-Clearwater, FL    PUT  NextSong   \n",
       "2  257.41016  paid  Tampa-St. Petersburg-Clearwater, FL    PUT  NextSong   \n",
       "3  231.23546  paid  Tampa-St. Petersburg-Clearwater, FL    PUT  NextSong   \n",
       "4  216.76363  paid  Tampa-St. Petersburg-Clearwater, FL    PUT  NextSong   \n",
       "\n",
       "   registration  sessionId                                  song  status  \\\n",
       "0  1.540992e+12        829                     Jim Henson's Dead     200   \n",
       "1  1.540558e+12       1049                           Shell Shock     200   \n",
       "2  1.540558e+12       1049  Women Lose Weight (Feat: Slick Rick)     200   \n",
       "3  1.540558e+12       1049             Won't Go Home Without You     200   \n",
       "4  1.540558e+12       1049                      Hey_ Soul Sister     200   \n",
       "\n",
       "              ts                                          userAgent userId  \n",
       "0  1543537327796  Mozilla/5.0 (compatible; MSIE 10.0; Windows NT...     91  \n",
       "1  1543540121796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     73  \n",
       "2  1543540368796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     73  \n",
       "3  1543540625796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     73  \n",
       "4  1543540856796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     73  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "      <th>userId</th>\n",
       "      <th>level</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>location</th>\n",
       "      <th>userAgent</th>\n",
       "      <th>song</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-11-30 00:22:07.796</td>\n",
       "      <td>91</td>\n",
       "      <td>free</td>\n",
       "      <td>829</td>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "      <td>Mozilla/5.0 (compatible; MSIE 10.0; Windows NT...</td>\n",
       "      <td>Jim Henson's Dead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-11-30 01:08:41.796</td>\n",
       "      <td>73</td>\n",
       "      <td>paid</td>\n",
       "      <td>1049</td>\n",
       "      <td>Tampa-St. Petersburg-Clearwater, FL</td>\n",
       "      <td>\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>\n",
       "      <td>Shell Shock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-11-30 01:12:48.796</td>\n",
       "      <td>73</td>\n",
       "      <td>paid</td>\n",
       "      <td>1049</td>\n",
       "      <td>Tampa-St. Petersburg-Clearwater, FL</td>\n",
       "      <td>\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>\n",
       "      <td>Women Lose Weight (Feat: Slick Rick)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-11-30 01:17:05.796</td>\n",
       "      <td>73</td>\n",
       "      <td>paid</td>\n",
       "      <td>1049</td>\n",
       "      <td>Tampa-St. Petersburg-Clearwater, FL</td>\n",
       "      <td>\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>\n",
       "      <td>Won't Go Home Without You</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-11-30 01:20:56.796</td>\n",
       "      <td>73</td>\n",
       "      <td>paid</td>\n",
       "      <td>1049</td>\n",
       "      <td>Tampa-St. Petersburg-Clearwater, FL</td>\n",
       "      <td>\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>\n",
       "      <td>Hey_ Soul Sister</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ts userId level  sessionId  \\\n",
       "0 2018-11-30 00:22:07.796     91  free        829   \n",
       "1 2018-11-30 01:08:41.796     73  paid       1049   \n",
       "2 2018-11-30 01:12:48.796     73  paid       1049   \n",
       "3 2018-11-30 01:17:05.796     73  paid       1049   \n",
       "4 2018-11-30 01:20:56.796     73  paid       1049   \n",
       "\n",
       "                              location  \\\n",
       "0      Dallas-Fort Worth-Arlington, TX   \n",
       "1  Tampa-St. Petersburg-Clearwater, FL   \n",
       "2  Tampa-St. Petersburg-Clearwater, FL   \n",
       "3  Tampa-St. Petersburg-Clearwater, FL   \n",
       "4  Tampa-St. Petersburg-Clearwater, FL   \n",
       "\n",
       "                                           userAgent  \\\n",
       "0  Mozilla/5.0 (compatible; MSIE 10.0; Windows NT...   \n",
       "1  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...   \n",
       "2  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...   \n",
       "3  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...   \n",
       "4  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...   \n",
       "\n",
       "                                   song  \n",
       "0                     Jim Henson's Dead  \n",
       "1                           Shell Shock  \n",
       "2  Women Lose Weight (Feat: Slick Rick)  \n",
       "3             Won't Go Home Without You  \n",
       "4                      Hey_ Soul Sister  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting songplay data\n",
    "records_df = df[['ts', 'userId', 'level', 'sessionId','location' ,'userAgent', 'song']]\n",
    "records_df['ts'] = pd.to_datetime(records_df['ts'] , unit='ms')\n",
    "records_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "records_fname = 'records.csv'\n",
    "\n",
    "# Saving the data into a csv file\n",
    "records_df.to_csv(records_fname, index=False) # Removing the extra csv index between to match the columns for bulk data insert\n",
    "\n",
    "# Getting the current working directory path\n",
    "working_dir = os.getcwd()\n",
    "\n",
    "records_data_path = f\"{working_dir}/{records_fname}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Copying the songplay data from the csv file into the database table\n",
    "with open(records_data_path, 'r') as f:\n",
    "    cur.copy_expert(sql=songplay_table_bulk_insert, file=f)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Close Connection to Sparkify Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Implement `etl.py`\n",
    "Use what you've completed in this notebook to implement `etl.py`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
